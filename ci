#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "click>=8.1.0",
#     "rich>=13.0.0",
# ]
# ///
"""Build and test tools for the Bazel test set rules project.

Container commands (build, test, check, query) can be run from the host
(auto-delegates into the container) or directly inside the container
(e.g. after ./ci shell).
"""

from __future__ import annotations

import fcntl
import grp
import os
import pwd
import shlex
import shutil
import subprocess
import sys
import time
from pathlib import Path

import click
from rich.console import Console

PROJECT_ROOT = Path(__file__).parent.resolve()
TARGET_DIR = PROJECT_ROOT / "target"
IMAGE_NAME = "test-sets-bazel-devenv"
DOCKERFILE = PROJECT_ROOT / "Dockerfile.devenv"
IN_CONTAINER = os.environ.get("IN_CONTAINER") == "1"

console = Console()


def run_cmd(
    cmd: list[str], check: bool = True, **kwargs
) -> subprocess.CompletedProcess:
    """Run a command with logging."""
    console.print(f"[dim]$ {' '.join(cmd)}[/dim]")
    try:
        return subprocess.run(cmd, check=check, text=True, **kwargs)
    except subprocess.CalledProcessError as e:
        console.print(f"[red]Command failed with exit code {e.returncode}[/red]")
        raise


def _docker_build_cmd(extra_args: list[str] | None = None) -> list[str]:
    """Return the base docker build command with UID/GID build args."""
    cmd = [
        "docker", "build",
        "--build-arg", f"HOST_UID={os.getuid()}",
        "--build-arg", f"HOST_GID={os.getgid()}",
        "--build-arg", f"HOST_USER={pwd.getpwuid(os.getuid()).pw_name}",
        "--build-arg", f"HOST_GROUP={grp.getgrgid(os.getgid()).gr_name}",
    ]
    if extra_args:
        cmd.extend(extra_args)
    cmd.extend(["-t", IMAGE_NAME, "-f", str(DOCKERFILE), str(PROJECT_ROOT)])
    return cmd


def _find_running_containers() -> list[str]:
    """Return container IDs running from the CI image."""
    result = subprocess.run(
        ["docker", "ps", "-q", "--filter", f"ancestor={IMAGE_NAME}"],
        capture_output=True, text=True,
    )
    return result.stdout.strip().split("\n") if result.stdout.strip() else []


def _kill_stale_containers():
    """Kill running CI containers and clear the lock file."""
    containers = _find_running_containers()
    if not containers:
        return
    console.print(f"[yellow]Killing {len(containers)} stale container(s)...[/yellow]")
    subprocess.run(["docker", "kill", *containers], capture_output=True)
    lock_path = TARGET_DIR / ".ci.lock"
    if lock_path.exists():
        lock_path.unlink()


PROFILE_TIMINGS_FILE = TARGET_DIR / ".profile_timings.json"


def _timed(label: str, func, *args, **kwargs):
    """Run *func* and return (result, elapsed_seconds)."""
    t0 = time.monotonic()
    result = func(*args, **kwargs)
    return result, time.monotonic() - t0


def build_image():
    """Build Docker image, relying on Docker layer cache to skip unchanged layers."""
    if not DOCKERFILE.exists():
        console.print(
            f"[red]Dockerfile not found: {DOCKERFILE.relative_to(PROJECT_ROOT)}[/red]"
        )
        sys.exit(1)
    run_cmd(_docker_build_cmd())


def _delegate_to_container(args: list[str], force: bool = False):
    """Build image and re-invoke ./ci inside the container.

    Acquires an exclusive file lock so only one container runs at a time.
    Checks for stale containers before starting and cleans up after.
    """
    build_image()
    TARGET_DIR.mkdir(exist_ok=True)

    # Pre-flight: check for stale containers
    stale = _find_running_containers()
    if stale:
        if force:
            _kill_stale_containers()
        else:
            console.print(
                "[red]Stale container(s) detected from a previous run.[/red]\n"
                "[red]Run with --force to kill them, or manually: "
                f"docker kill {' '.join(stale)}[/red]"
            )
            sys.exit(1)

    lock_path = TARGET_DIR / ".ci.lock"
    with open(lock_path, "w") as lock_fd:
        try:
            fcntl.flock(lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
        except OSError:
            console.print("[red]Another ./ci command is already running.[/red]")
            sys.exit(1)
        ci_cmd = "./ci " + " ".join(shlex.quote(a) for a in args)
        try:
            run_cmd([
                "docker", "run", "--rm",
                "-v", f"{PROJECT_ROOT}:/workspace:rw",
                "-w", "/workspace",
                IMAGE_NAME,
                ci_cmd,
            ])
        finally:
            # Post-run: verify container was cleaned up
            leftover = _find_running_containers()
            if leftover:
                console.print(
                    f"[yellow]Warning: {len(leftover)} container(s) still running "
                    f"after command completed. Cleaning up...[/yellow]"
                )
                _kill_stale_containers()


def _require_host(cmd_name: str):
    """Exit with error if running inside the container."""
    if IN_CONTAINER:
        console.print(f"[red]'{cmd_name}' can only be run from the host.[/red]")
        sys.exit(1)


def _clean_stale_bazel_symlinks():
    """Remove stale Bazel convenience symlinks that point to inaccessible locations."""
    for item in PROJECT_ROOT.iterdir():
        if item.is_symlink() and item.name.startswith("bazel-"):
            try:
                if item.resolve().exists():
                    continue
            except PermissionError:
                pass
            item.unlink()
            console.print(f"[dim]Removed stale symlink {item.name}[/dim]")


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

@click.group()
@click.option("--force", is_flag=True, help="Kill stale containers before running.")
@click.pass_context
def cli(ctx, force):
    """Build and test tools for the Bazel test set rules project."""
    ctx.ensure_object(dict)
    ctx.obj["force"] = force


# ---------------------------------------------------------------------------
# Container commands — run directly when IN_CONTAINER, delegate otherwise
# ---------------------------------------------------------------------------

@cli.command()
@click.pass_context
def build(ctx):
    """Build all Bazel targets."""
    if not IN_CONTAINER:
        _delegate_to_container(["build"], force=ctx.obj["force"])
        return
    _clean_stale_bazel_symlinks()
    run_cmd(["bazel", "build", "//..."])


@cli.command()
@click.option("--profile", is_flag=True, help="Print wall-clock timing breakdown of each phase.")
@click.pass_context
def test(ctx, profile):
    """Run all Bazel tests and Python unit tests."""
    if not IN_CONTAINER:
        args = ["test"]
        if profile:
            args.append("--profile")
            # Remove stale timings so we don't show old data on failure
            PROFILE_TIMINGS_FILE.parent.mkdir(exist_ok=True)
            if PROFILE_TIMINGS_FILE.exists():
                PROFILE_TIMINGS_FILE.unlink()

            _, dt_build = _timed("docker_build", build_image)

            # Inline the container-run part of _delegate_to_container so we
            # can time it separately from the image build.
            force = ctx.obj["force"]
            stale = _find_running_containers()
            if stale:
                if force:
                    _kill_stale_containers()
                else:
                    console.print(
                        "[red]Stale container(s) detected. Run with --force to kill them.[/red]"
                    )
                    sys.exit(1)

            TARGET_DIR.mkdir(exist_ok=True)
            lock_path = TARGET_DIR / ".ci.lock"
            with open(lock_path, "w") as lock_fd:
                try:
                    fcntl.flock(lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
                except OSError:
                    console.print("[red]Another ./ci command is already running.[/red]")
                    sys.exit(1)
                ci_cmd = "./ci " + " ".join(shlex.quote(a) for a in args)
                try:
                    _, dt_container = _timed(
                        "container_run",
                        run_cmd,
                        [
                            "docker", "run", "--rm",
                            "-v", f"{PROJECT_ROOT}:/workspace:rw",
                            "-w", "/workspace",
                            IMAGE_NAME,
                            ci_cmd,
                        ],
                    )
                finally:
                    leftover = _find_running_containers()
                    if leftover:
                        _kill_stale_containers()

            # Read container-side timings and print combined summary
            import json as json_mod
            container_timings: list[tuple[str, float]] = []
            if PROFILE_TIMINGS_FILE.exists():
                container_timings = json_mod.loads(
                    PROFILE_TIMINGS_FILE.read_text()
                )

            console.print()
            console.print("[bold]===== Profile: wall-clock timing =====[/bold]")
            timings: list[tuple[str, float]] = [
                ("docker build (image)", dt_build),
            ]
            for label, dt in container_timings:
                timings.append((f"  {label}", dt))
            timings.append(("docker run  (total)", dt_container))
            for label, dt in timings:
                console.print(f"  {label:<40s} {dt:>7.1f}s")
            total = dt_build + dt_container
            console.print(f"  {'TOTAL':<40s} {total:>7.1f}s")
            return

        _delegate_to_container(args, force=ctx.obj["force"])
        return

    # --- Inside container ---
    timings: list[tuple[str, float]] = []

    _clean_stale_bazel_symlinks()
    _, dt = _timed("bazel test //...", run_cmd, ["bazel", "test", "//..."])
    timings.append(("bazel test //...", dt))

    console.print("[bold]--- Running pytest ---[/bold]")
    pytest_args = [
        "pytest", "orchestrator/", "ci_tool/", "tests/",
        "-v", "--tb=short",
    ]
    _, dt = _timed("pytest", run_cmd, pytest_args)
    timings.append(("pytest", dt))

    if profile:
        import json as json_mod
        PROFILE_TIMINGS_FILE.parent.mkdir(exist_ok=True)
        PROFILE_TIMINGS_FILE.write_text(json_mod.dumps(timings))


@cli.command()
@click.pass_context
def check(ctx):
    """Run type checks."""
    if not IN_CONTAINER:
        _delegate_to_container(["check"], force=ctx.obj["force"])
        return
    run_cmd([
        "mypy", "orchestrator/", "ci_tool/", "tests/",
        "--ignore-missing-imports",
    ])


@cli.command("test-examples")
@click.pass_context
def test_examples(ctx):
    """Run Bazel tests, lifecycle demo (burn-in/demotion/recovery), and reports."""
    if not IN_CONTAINER:
        _delegate_to_container(["test-examples"], force=ctx.obj["force"])
        return
    examples_dir = PROJECT_ROOT / "examples"
    for item in examples_dir.iterdir():
        if item.is_symlink() and item.name.startswith("bazel-"):
            try:
                if item.resolve().exists():
                    continue
            except PermissionError:
                pass
            item.unlink()
            console.print(f"[dim]Removed stale symlink examples/{item.name}[/dim]")

    status_path = examples_dir / "ecommerce" / ".tests" / "status"
    email_label = "@@//ecommerce:email_notification_raw_test"

    # Phase 1: Clean start + Bazel validation
    console.print("[bold]--- Phase 1: Clean start + Bazel validation ---[/bold]")
    shutil.rmtree(status_path.parent, ignore_errors=True)
    console.print("[dim]Removed .tests/ directory[/dim]")
    run_cmd(["bazel", "test", "//..."], cwd=str(examples_dir))

    # Phase 2: Burn-in acceptance (email: burning_in → stable)
    # Pre-seed 27/27 passes; one orchestrator run tips SPRT to accept.
    console.print("[bold]--- Phase 2: Burn-in acceptance ---[/bold]")
    _setup_burnin_status(status_path, email_label)
    run_cmd(
        [
            "bazel", "run", "//ecommerce:ecommerce_tests", "--",
            "--status-file", str(status_path), "--allow-dirty",
        ],
        cwd=str(examples_dir),
    )
    _print_lifecycle_summary(status_path, "after burn-in acceptance")

    # Phase 3: Degradation → demotion (email: stable → flaky)
    # Inject failure history (simulating bad CI runs), then run with degraded
    # reliability so the current run also fails → demotion triggers.
    console.print("[bold]--- Phase 3: Degradation and demotion ---[/bold]")
    _inject_degradation(status_path, email_label)
    env = dict(os.environ)
    env["TST_EMAIL_RELIABILITY"] = "0.0"
    run_cmd(
        [
            "bazel", "run", "//ecommerce:ecommerce_tests", "--",
            "--status-file", str(status_path), "--allow-dirty",
        ],
        cwd=str(examples_dir),
        env=env,
        check=False,  # email_notification will fail — expect non-zero exit
    )
    _print_lifecycle_summary(status_path, "after degradation")

    # Phase 4: Fix + re-burn-in (email: burning_in → stable again)
    # Simulate: developer fixes root cause, CI tool deflakes the test,
    # 27 clean burn-in runs accumulate, then this run tips acceptance.
    console.print("[bold]--- Phase 4: Fix and re-stabilization ---[/bold]")
    _setup_deflake_status(status_path, email_label)
    run_cmd(
        [
            "bazel", "run", "//ecommerce:ecommerce_tests", "--",
            "--status-file", str(status_path), "--allow-dirty",
        ],
        cwd=str(examples_dir),
    )
    _print_lifecycle_summary(status_path, "after re-stabilization")

    # Phase 5: Generate reports for other examples
    console.print("[bold]--- Phase 5: Other example reports ---[/bold]")
    run_cmd(
        ["bazel", "run", "//macros_demo:deployment_validation"],
        cwd=str(examples_dir),
    )


def _setup_burnin_status(status_path: Path, email_label: str) -> None:
    """Create status file with email_notification in burn-in, one pass from SPRT accept."""
    import json as json_mod

    status = {
        "config": {
            "min_reliability": 0.99,
            "statistical_significance": 0.95,
        },
        "tests": {
            email_label: {
                "state": "burning_in",
                "history": [
                    {"passed": True, "commit": None} for _ in range(27)
                ],
                "last_updated": "2026-02-16T12:00:00+00:00",
            },
        },
    }

    status_path.parent.mkdir(parents=True, exist_ok=True)
    status_path.write_text(json_mod.dumps(status, indent=2) + "\n")
    console.print(f"[dim]  {email_label}: burning_in (27/27 — one pass from acceptance)[/dim]")


def _inject_degradation(status_path: Path, email_label: str) -> None:
    """Inject recent failures into email_notification history.

    Simulates several CI runs where a bad commit caused the test to fail.
    """
    import json as json_mod

    data = json_mod.loads(status_path.read_text())
    entry = data["tests"].get(email_label)
    if entry is None:
        console.print(f"[red]Warning: {email_label} not found in status file[/red]")
        return

    for _ in range(5):
        entry["history"].insert(0, {"passed": False, "commit": "bad-commit"})

    status_path.write_text(json_mod.dumps(data, indent=2) + "\n")
    console.print(
        f"[dim]  Injected 5 failures into {email_label} history "
        f"(simulating degraded CI runs)[/dim]"
    )


def _setup_deflake_status(status_path: Path, email_label: str) -> None:
    """Reset email_notification to burning_in for re-stabilization.

    Simulates: developer fixes root cause, CI tool deflakes the test,
    then 27 successful burn-in runs accumulate in subsequent CI runs.
    """
    import json as json_mod

    data = json_mod.loads(status_path.read_text())
    data["tests"][email_label] = {
        "state": "burning_in",
        "history": [
            {"passed": True, "commit": None} for _ in range(27)
        ],
        "last_updated": "2026-02-16T14:00:00+00:00",
    }
    status_path.write_text(json_mod.dumps(data, indent=2) + "\n")
    console.print(
        f"[dim]  {email_label}: reset to burning_in "
        f"(27/27 — simulating deflake + re-burn-in)[/dim]"
    )


def _print_lifecycle_summary(status_path: Path, phase_label: str = "") -> None:
    """Print a summary of the status file after a lifecycle phase."""
    import json as json_mod

    header = "Lifecycle summary"
    if phase_label:
        header += f" ({phase_label})"
    console.print(f"[bold]{header}[/bold]")

    try:
        data = json_mod.loads(status_path.read_text())
    except (FileNotFoundError, json_mod.JSONDecodeError) as e:
        console.print(f"[red]Could not read status file: {e}[/red]")
        return

    tests = data.get("tests", {})
    state_counts: dict[str, int] = {}
    for name, entry in sorted(tests.items()):
        state = entry.get("state", "unknown")
        history = entry.get("history", [])
        runs = len(history)
        passes = sum(1 for h in history if h.get("passed", False))
        state_counts[state] = state_counts.get(state, 0) + 1
        short_name = name.split(":")[-1] if ":" in name else name
        if state == "stable":
            console.print(f"  [green]{short_name}: {state} ({runs} runs, {passes} passes)[/green]")
        elif state == "flaky":
            console.print(f"  [red]{short_name}: {state} ({runs} runs, {passes} passes)[/red]")
        elif state == "burning_in":
            console.print(f"  [yellow]{short_name}: {state} ({runs} runs, {passes} passes)[/yellow]")
        else:
            console.print(f"  [dim]{short_name}: {state} ({runs} runs)[/dim]")

    console.print()
    summary = ", ".join(f"{count} {state}" for state, count in sorted(state_counts.items()))
    console.print(f"[bold]Status summary: {summary}[/bold]")
    console.print()


@cli.command()
@click.argument("pattern", default="//...")
@click.pass_context
def query(ctx, pattern):
    """Query Bazel targets.

    PATTERN is a Bazel query expression (default: //...).
    Examples:
        ./ci query '//macros/examples:*'
        ./ci query 'kind(test, //...)'
    """
    if not IN_CONTAINER:
        _delegate_to_container(["query", pattern], force=ctx.obj["force"])
        return
    _clean_stale_bazel_symlinks()
    run_cmd(["bash", "-c", f"bazel query {shlex.quote(pattern)} 2>/dev/null | sort"])


# ---------------------------------------------------------------------------
# Host-only commands
# ---------------------------------------------------------------------------

@cli.command()
def shell():
    """Launch an interactive shell in the container."""
    _require_host("shell")
    build_image()
    run_cmd([
        "docker", "run", "--rm", "-it",
        "-v", f"{PROJECT_ROOT}:/workspace:rw",
        "-w", "/workspace",
        "--entrypoint", "bash",
        IMAGE_NAME,
    ])


@cli.command()
def clean():
    """Remove all generated files in target directory."""
    _require_host("clean")
    if TARGET_DIR.exists():
        shutil.rmtree(TARGET_DIR)
        TARGET_DIR.mkdir()
        console.print(
            f"[yellow]Cleaned {TARGET_DIR.relative_to(PROJECT_ROOT)}/[/yellow]"
        )
    else:
        TARGET_DIR.mkdir()
        console.print("[dim]Nothing to clean[/dim]")


@cli.command()
def kill():
    """Kill any stale CI containers."""
    _require_host("kill")
    containers = _find_running_containers()
    if not containers:
        console.print("[dim]No stale containers found.[/dim]")
        return
    _kill_stale_containers()
    console.print("[green]Stale containers killed.[/green]")


@cli.command("rebuild-image")
def rebuild_image():
    """Force rebuild Docker image."""
    _require_host("rebuild-image")
    if not DOCKERFILE.exists():
        console.print(
            f"[red]Dockerfile not found: {DOCKERFILE.relative_to(PROJECT_ROOT)}[/red]"
        )
        sys.exit(1)
    console.print(f"Rebuilding [bold]{IMAGE_NAME}[/bold]...")
    run_cmd(_docker_build_cmd(["--no-cache"]))
    console.print("[green]Image rebuilt[/green]")


if __name__ == "__main__":
    cli()
